<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>

  <title>Train-Skill-Embeddings</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Practical Approach to Word Embeddings using Word2Vec and Genism</name>
              </p>
              <p> By <i> Harsh Panwar </i>
              </p>
              <p> Dec 15,2019 - 5 min read </p>
              
              <p style="text-align:center">
                <a href="mailto:harshpanwar@ieee.org">Email</a> &nbsp/&nbsp
                <a href="https://github.com/Harsh9524/Harsh9524.github.io/blob/master/data/CV_Harsh_Panwar.pdf">CV</a> &nbsp/&nbsp
                <a href="https://www.researchgate.net/profile/Harsh_Panwar2">ResearchGate</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=g0UG174AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.github.com/Harsh9524">Github</a> &nbsp/&nbsp
                <a href="https://www.instagram.com/harsh_.panwar/">Instagram</a>
                <!-- <a href="https://www.linkedin.com/in/harsh-panwar/">LinkedIn</a> -->
              </p>
            </td>
<!--             <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/JonBarron.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/dp_circle.png" class="hoverZoomLink"></a>
            </td> -->
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Introduction</heading>
              <p>
                ord Embeddings are used to make a relation between a bag of words which are related to each other in some
sense. For instance if there is a dataset of 100 candidates containing skills of each candidate in the form of a list, using word embeddings we can make a relation between each word so that Java and C++ are more related than Java and Business Development.
Word embedding is the collective name for a set of language modeling and feature learning techniques in natural language processing (NLP) where words or phrases from the vocabulary are mapped to vectors of real numbers. Conceptually it involves a mathematical embedding from a space with many dimensions per word to a continuous vector space with a much lower dimension.

So with the help of a practical example I will try to explain the concepts of Word Embeddings. I have used Word2Vec as the algorithm implemented through Gensim. The full Github repo is available here.

                <!-- <span class="highlight">highlighted</span>. -->
              </p>
            </td>
          </tr>
        </tbody></table>
       
       
      </td>
    </tr>
  </table>
</body>

</html>
